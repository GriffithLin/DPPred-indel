{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4f2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3517e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AlbertConfig,\n",
    "    AlbertForSequenceClassification,\n",
    "    AlbertTokenizer,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification, \n",
    "    BertForSequenceClassification_textCNN,\n",
    "    BertForLongSequenceClassification,\n",
    "    BertForLongSequenceClassificationCat,\n",
    "    BertTokenizer,\n",
    "    DNATokenizer,\n",
    "    DistilBertConfig,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    FlaubertConfig,\n",
    "    FlaubertForSequenceClassification,\n",
    "    FlaubertTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForSequenceClassification,\n",
    "    RobertaTokenizer,\n",
    "    XLMConfig,\n",
    "    XLMForSequenceClassification,\n",
    "    XLMRobertaConfig,\n",
    "    XLMRobertaForSequenceClassification,\n",
    "    XLMRobertaTokenizer,\n",
    "    XLMTokenizer,\n",
    "    XLNetConfig,\n",
    "    XLNetForSequenceClassification,\n",
    "    XLNetTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from transformers import glue_processors as processors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e88bc",
   "metadata": {},
   "source": [
    "--model_type\n",
    "dnatextcnn\n",
    "--model_num\n",
    "1\n",
    "--tokenizer_name=dna5\n",
    "--model_name_or_path\n",
    "/data3/linming/DNABERT/examples/embeding_model/5-new-12w-0/\n",
    "--task_name\n",
    "dnaprom\n",
    "--do_train\n",
    "--do_eval\n",
    "--data_dir\n",
    "/data3/linming/DNABERT/examples/data/fold5_100_2506+10020_5/fea/after/\n",
    "--max_seq_length\n",
    "250\n",
    "--per_gpu_eval_batch_size=32\n",
    "--per_gpu_train_batch_size=32\n",
    "--learning_rate\n",
    "1e-4\n",
    "--num_train_epochs\n",
    "5\n",
    "--output_dir\n",
    "/data3/linming/DNABERT/examples/output/100_2506+10020_5_dna_textcnn_last_four/\n",
    "--evaluate_during_training\n",
    "--logging_steps\n",
    "100\n",
    "--save_steps\n",
    "4000\n",
    "--warmup_percent\n",
    "0.1\n",
    "--hidden_dropout_prob\n",
    "0.1\n",
    "--overwrite_output\n",
    "--weight_decay\n",
    "0.01\n",
    "--n_process\n",
    "8\n",
    "--model_name\n",
    "mutant_Bert_100_2506+10020_5_dnatextcnn_last_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.max_seq_length = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ac01b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        GGCCT GCCTT CCTTC CTTCC TTCCC TCCCG CCCGC CCGC...\n",
       "1        TCGCA CGCAG GCAGC CAGCC AGCCC GCCCA CCCAC CCAC...\n",
       "2        GGGAC GGACC GACCC ACCCC CCCCC CCCCA CCCAT CCAT...\n",
       "3        CTGGC TGGCA GGCAG GCAGA CAGAG AGAGG GAGGG AGGG...\n",
       "4        CAACA AACAG ACAGA CAGAT AGATC GATCA ATCAA TCAA...\n",
       "                               ...                        \n",
       "11308    CCTCT CTCTC TCTCG CTCGG TCGGT CGGTG GGTGA GTGA...\n",
       "11309    AATGT ATGTT TGTTT GTTTG TTTGG TTGGA TGGAC GGAC...\n",
       "11310    GCATG CATGG ATGGG TGGGG GGGGG GGGGG GGGGC GGGC...\n",
       "11311    AGTGG GTGGC TGGCA GGCAG GCAGC CAGCG AGCGC GCGC...\n",
       "11312    AGTGG GTGGC TGGCA GGCAG GCAGC CAGCG AGCGC GCGC...\n",
       "Name: sequence, Length: 11313, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_data_direction = \"/data3/linming/DNA_Lin/dataCenter/NotContext/5/225/\"\n",
    "train_dna_data_path = os.path.join(dna_data_direction, \"train.tsv\")\n",
    "train_dna_data = pd.read_csv(train_dna_data_path, sep=\"\\t\")[\"sequence\"]\n",
    "train_dna_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a19b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "<class 'transformers.tokenization_dna.DNATokenizer'>\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"/data3/linming/DNABERT/examples/embeding_model/5-new-12w-0/\"\n",
    "tokenizer = DNATokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    do_lower_case=False,\n",
    "    cache_dir= None,\n",
    ")\n",
    "pad_token = tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0]\n",
    "task = \"dnaprom\"\n",
    "processor = processors[task]()\n",
    "label_list = processor.get_labels()\n",
    "max_length = args.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = convert_examples_to_features(\n",
    "examples,\n",
    "tokenizer,\n",
    "label_list=label_list,\n",
    "max_length=max_length,\n",
    "output_mode=output_mode,\n",
    "pad_on_left=pad_on_left,  # pad on the left for xlnet\n",
    "pad_token=pad_token,\n",
    "pad_token_segment_id=pad_token_segment_id,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac92909",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "if output_mode == \"classification\":\n",
    "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "elif output_mode == \"regression\":\n",
    "    all_labels = torch.tensor([f.label for f in features], dtype=torch.float)\n",
    "\n",
    "dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "dnabert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
